{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell A: install python packages\n",
        "!pip install -q streamlit reportlab pandas matplotlib\n",
        "# optional: reduce log spam"
      ],
      "metadata": {
        "id": "emeZ2SzeimjL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "L8B49QX2pDnO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "RMfuY-BXvLi8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: save a minimal Streamlit app (replace later with your full app)\n",
        "app_code = r\"\"\"\n",
        "import streamlit as st\n",
        "st.set_page_config(page_title=\"CyberMind\", layout=\"wide\")\n",
        "st.title(\"CyberMind Dashboard (test)\")\n",
        "st.write(\"If you see this, Streamlit is running.\")\n",
        "\"\"\"\n",
        "with open(\"app.py\",\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"Saved app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPLaUeFbi5Lu",
        "outputId": "410e3bee-9b8d-42f5-e832-5f014307ba5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# app.py ‚Äî CyberMind Streamlit Dashboard (same UI, with auto AI enrichment on upload)\n",
        "\n",
        "import io, json, re\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Page setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "st.set_page_config(page_title=\"CyberMind Dashboard\", page_icon=\"üõ°\", layout=\"wide\")\n",
        "PRIMARY = \"#0B5ED7\"; ACCENT = \"#22B07D\"; MUTED = \"#6c757d\"\n",
        "st.markdown(f\"\"\"\n",
        "<style>\n",
        ".cm-badge {{display:inline-block;padding:4px 10px;border-radius:999px;background:{ACCENT}15;color:{ACCENT};\n",
        "            font-weight:600;font-size:12px;border:1px solid {ACCENT}55;}}\n",
        ".cm-card {{border:1px solid #e9ecef;padding:16px;border-radius:12px;background:white;}}\n",
        ".cm-h1 {{font-size:28px;font-weight:800;color:{PRIMARY};margin-bottom:0}}\n",
        ".cm-sub {{color:{MUTED};font-size:13px}}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Demo data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "DEMO_DATA = [\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-59248\",\n",
        "        \"title\": \"Microsoft Exchange Server ‚Äì spoofing & auth issues\",\n",
        "        \"description\": \"Multiple high-severity issues in Exchange may enable spoofing and privilege escalation.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:L\",\n",
        "        \"priority\": \"High\",\n",
        "        \"effort\": \"Medium\",\n",
        "        \"mitigations\": [\n",
        "            \"Apply latest Microsoft security updates.\",\n",
        "            \"Enforce strong authentication & input validation.\",\n",
        "            \"Audit logs for suspicious auth flows.\"\n",
        "        ],\n",
        "        \"references\": [\"https://msrc.microsoft.com/update-guide/\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-53782\",\n",
        "        \"title\": \"SQL Injection in Product X\",\n",
        "        \"description\": \"Insufficient sanitization allows SQL injection in login workflow.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\",\n",
        "        \"priority\": \"High\",\n",
        "        \"effort\": \"Medium\",\n",
        "        \"mitigations\": [\n",
        "            \"Use parameterized queries / prepared statements.\",\n",
        "            \"Centralize input validation.\",\n",
        "            \"WAF rules for SQLi signatures.\"\n",
        "        ],\n",
        "        \"references\": [\"https://owasp.org/www-community/attacks/SQL_Injection\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "    {\n",
        "        \"cve_id\": \"CVE-2025-55999\",\n",
        "        \"title\": \"Outdated 3rd-party library in backend\",\n",
        "        \"description\": \"Known vulnerable dependency may lead to RCE under certain configs.\",\n",
        "        \"cvss_v3\": \"CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H\",\n",
        "        \"priority\": \"Medium\",\n",
        "        \"effort\": \"Low\",\n",
        "        \"mitigations\": [\n",
        "            \"Upgrade dependency to a patched version.\",\n",
        "            \"Pin versions and enable Dependabot.\",\n",
        "            \"SBOM + regular SCA scans.\"\n",
        "        ],\n",
        "        \"references\": [\"https://nvd.nist.gov/\"],\n",
        "        \"source\": \"Demo\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Helpers (upgraded) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "def ensure_list(x):\n",
        "    if x is None: return []\n",
        "    if isinstance(x, list): return x\n",
        "    return [x]\n",
        "\n",
        "def _try_float(x):\n",
        "    try: return float(x)\n",
        "    except: return None\n",
        "\n",
        "def extract_cvss_score(it: dict) -> float|None:\n",
        "    # direct numeric\n",
        "    for k in [\"cvss_score\",\"cvssScore\",\"baseScore\"]:\n",
        "        if k in it:\n",
        "            s = _try_float(it[k])\n",
        "            if s is not None: return s\n",
        "    # vector-like strings\n",
        "    for k in [\"cvss_v3\",\"cvss\",\"cvssVector\"]:\n",
        "        v = it.get(k)\n",
        "        if isinstance(v, str):\n",
        "            m = re.search(r\"(\\d+\\.\\d+)\", v)\n",
        "            if m: return _try_float(m.group(1))\n",
        "    # severity arrays\n",
        "    sev = it.get(\"severity\")\n",
        "    if isinstance(sev, list):\n",
        "        for s in sev:\n",
        "            if isinstance(s, dict):\n",
        "                for kk in [\"score\",\"baseScore\",\"value\"]:\n",
        "                    sc = _try_float(s.get(kk))\n",
        "                    if sc is not None: return sc\n",
        "                txt = \" \".join([str(x) for x in s.values() if isinstance(x, str)])\n",
        "                m = re.search(r\"(\\d+\\.\\d+)\", txt)\n",
        "                if m: return _try_float(m.group(1))\n",
        "    # NVD metrics trees\n",
        "    metrics = it.get(\"metrics\") or {}\n",
        "    if isinstance(metrics, dict):\n",
        "        for key in [\"cvssMetricV31\",\"cvssMetricV30\",\"cvssMetricV2\"]:\n",
        "            arr = metrics.get(key)\n",
        "            if isinstance(arr, list) and arr:\n",
        "                data = arr[0].get(\"cvssData\") if isinstance(arr[0], dict) else None\n",
        "                if isinstance(data, dict) and \"baseScore\" in data:\n",
        "                    sc = _try_float(data[\"baseScore\"])\n",
        "                    if sc is not None: return sc\n",
        "    # fallback: scan any string\n",
        "    for v in it.values():\n",
        "        if isinstance(v, str):\n",
        "            m = re.search(r\"(\\d+\\.\\d+)\", v)\n",
        "            if m: return _try_float(m.group(1))\n",
        "    return None\n",
        "\n",
        "def priority_from_cvss(score: float|None) -> str:\n",
        "    if score is None: return \"Unknown\"\n",
        "    if score >= 9.0:  return \"Critical\"\n",
        "    if score >= 7.0:  return \"High\"\n",
        "    if score >= 4.0:  return \"Medium\"\n",
        "    if score >  0.0:  return \"Low\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "MITIGATION_RULES = [\n",
        "    (r\"sql\\s*injection|sqli\", [\n",
        "        \"Use parameterized queries / prepared statements.\",\n",
        "        \"Centralize input validation & encoding.\",\n",
        "        \"Enable WAF rules for SQLi signatures.\"\n",
        "    ]),\n",
        "    (r\"\\bxss\\b|cross[-\\s]?site\", [\n",
        "        \"Encode untrusted data in HTML/JS contexts.\",\n",
        "        \"Use Content-Security-Policy (CSP).\",\n",
        "        \"Sanitize and validate all inputs.\"\n",
        "    ]),\n",
        "    (r\"\\brce\\b|remote code\", [\n",
        "        \"Patch vulnerable components immediately.\",\n",
        "        \"Run services with least privilege.\",\n",
        "        \"Restrict egress and monitor exec calls.\"\n",
        "    ]),\n",
        "    (r\"authentica|authorization|privilege\", [\n",
        "        \"Enforce MFA and strong authentication.\",\n",
        "        \"Harden session management and token TTL.\",\n",
        "        \"Apply least-privilege on roles.\"\n",
        "    ]),\n",
        "]\n",
        "\n",
        "def suggest_mitigations(text: str) -> list[str]:\n",
        "    text = (text or \"\").lower()\n",
        "    out = []\n",
        "    for pat, tips in MITIGATION_RULES:\n",
        "        if re.search(pat, text):\n",
        "            out.extend(tips)\n",
        "    # unique + cap length\n",
        "    return list(dict.fromkeys(out))[:6]\n",
        "\n",
        "def normalize_records(raw):\n",
        "    \"\"\"Normalize list[dict] to DataFrame with unified columns.\"\"\"\n",
        "    rows = []\n",
        "    for it in raw:\n",
        "        try:\n",
        "            cve_id = it.get(\"cve_id\") or it.get(\"id\") or it.get(\"CVE\") or it.get(\"cveId\") or \"\"\n",
        "            title  = it.get(\"title\") or it.get(\"summary\") or it.get(\"name\") or \"\"\n",
        "            desc   = it.get(\"description\") or it.get(\"details\") or it.get(\"desc\") or \"\"\n",
        "\n",
        "            # NVD CVE 5.x (containers.cna)\n",
        "            if not (title or desc):\n",
        "                cna = (it.get(\"containers\") or {}).get(\"cna\") or {}\n",
        "                if not title:\n",
        "                    title = cna.get(\"title\") or \"\"\n",
        "                if not desc:\n",
        "                    for d in ensure_list(cna.get(\"descriptions\")):\n",
        "                        if isinstance(d, dict) and d.get(\"lang\") == \"en\":\n",
        "                            desc = d.get(\"value\") or desc\n",
        "\n",
        "            cvss_vec = it.get(\"cvss_v3\") or it.get(\"cvss\") or \"\"\n",
        "            cvss_num = extract_cvss_score(it)\n",
        "\n",
        "            prio = (it.get(\"priority\") or \"\").title()\n",
        "            if not prio or prio == \"Unknown\":\n",
        "                prio = priority_from_cvss(cvss_num)\n",
        "\n",
        "            mit = ensure_list(it.get(\"mitigations\") or it.get(\"MitigationSteps\"))\n",
        "            if not mit:\n",
        "                mit = suggest_mitigations(f\"{title} {desc}\")\n",
        "\n",
        "            refs = ensure_list(it.get(\"references\"))\n",
        "\n",
        "            effort = (it.get(\"effort\") or \"Unknown\").title()\n",
        "            source = it.get(\"source\") or \"Uploaded\"\n",
        "\n",
        "            rows.append({\n",
        "                \"cve_id\": cve_id,\n",
        "                \"title\": title,\n",
        "                \"description\": desc,\n",
        "                \"cvss_v3\": cvss_vec,\n",
        "                \"priority\": prio,\n",
        "                \"effort\": effort,\n",
        "                \"mitigations\": \", \".join(mit) if mit else \"\",\n",
        "                \"references\": \", \".join(refs) if refs else \"\",\n",
        "                \"source\": source,\n",
        "                \"cvss_numeric\": cvss_num\n",
        "            })\n",
        "        except Exception:\n",
        "            continue\n",
        "    df = pd.DataFrame(rows)\n",
        "    if len(df) == 0:\n",
        "        return pd.DataFrame(columns=[\"cve_id\",\"title\",\"description\",\"cvss_v3\",\"priority\",\"effort\",\"mitigations\",\"references\",\"source\",\"cvss_numeric\"])\n",
        "    return df\n",
        "\n",
        "def load_any_file(uploaded):\n",
        "    name = uploaded.name.lower()\n",
        "    if name.endswith(\".json\"):\n",
        "        data = json.load(uploaded)\n",
        "        if isinstance(data, dict):\n",
        "            if \"items\" in data and isinstance(data[\"items\"], list):\n",
        "                return data[\"items\"]\n",
        "            return [data]\n",
        "        return data\n",
        "    elif name.endswith(\".csv\"):\n",
        "        df = pd.read_csv(uploaded)\n",
        "        return df.to_dict(orient=\"records\")\n",
        "    else:\n",
        "        st.warning(\"Please upload JSON or CSV.\")\n",
        "        return []\n",
        "\n",
        "def kpi_card(label, value, help_txt=None):\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <div class=\"cm-card\">\n",
        "          <div class=\"cm-sub\">{label}</div>\n",
        "          <div style=\"font-size:26px;font-weight:800;margin-top:2px\">{value}</div>\n",
        "          {f'<div class=\"cm-sub\" style=\"margin-top:4px\">{help_txt}</div>' if help_txt else ''}\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "def filter_dataframe(df, query, severities):\n",
        "    out = df.copy()\n",
        "    if query:\n",
        "        q = query.lower().strip()\n",
        "        mask = (\n",
        "            out[\"cve_id\"].str.lower().str.contains(q, na=False) |\n",
        "            out[\"title\"].str.lower().str.contains(q, na=False) |\n",
        "            out[\"description\"].str.lower().str.contains(q, na=False)\n",
        "        )\n",
        "        out = out[mask]\n",
        "    if severities and \"All\" not in severities:\n",
        "        out = out[out[\"priority\"].isin(severities)]\n",
        "    return out\n",
        "\n",
        "def make_pdf(df):\n",
        "    \"\"\"Generate in-memory PDF using reportlab.\"\"\"\n",
        "    try:\n",
        "        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, ListFlowable, ListItem\n",
        "        from reportlab.lib.styles import getSampleStyleSheet\n",
        "        from reportlab.lib import colors\n",
        "        from reportlab.lib.pagesizes import A4\n",
        "        from reportlab.lib.units import inch\n",
        "    except Exception:\n",
        "        st.error(\"reportlab is not installed on this environment.\")\n",
        "        return None, None\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    doc = SimpleDocTemplate(buf, pagesize=A4, leftMargin=36, rightMargin=36, topMargin=42, bottomMargin=36)\n",
        "    styles = getSampleStyleSheet()\n",
        "    Title  = styles[\"Title\"]; Title.fontSize = 22\n",
        "    H2     = styles[\"Heading2\"]; H2.fontSize = 14\n",
        "    Normal = styles[\"Normal\"]\n",
        "\n",
        "    story = []\n",
        "    story.append(Paragraph(\"CyberMind ‚Äî Consolidated Security Report\", Title))\n",
        "    ts = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
        "    story.append(Paragraph(f\"Generated: {ts}\", Normal))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    total = len(df)\n",
        "    high  = int((df[\"priority\"] == \"High\").sum()) if \"priority\" in df else 0\n",
        "    story.append(Paragraph(\"Executive Summary\", H2))\n",
        "    story.append(Paragraph(f\"Total findings: <b>{total}</b> | High: <b>{high}</b>\", Normal))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    # table\n",
        "    cols = [\"cve_id\",\"priority\",\"cvss_v3\",\"mitigations\"]\n",
        "    rows = [[\"CVE\",\"Priority\",\"CVSS\",\"Key Mitigations\"]]\n",
        "    for _, r in df.head(15).iterrows():\n",
        "        rows.append([\n",
        "            r.get(\"cve_id\",\"‚Äî\"),\n",
        "            r.get(\"priority\",\"Unknown\"),\n",
        "            r.get(\"cvss_v3\",\"‚Äî\"),\n",
        "            (r.get(\"mitigations\") or \"‚Äî\")[:180]\n",
        "        ])\n",
        "    tbl = Table(rows, repeatRows=1, colWidths=[1.5*inch, 0.9*inch, 1.0*inch, None])\n",
        "    tbl.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\",(0,0),(-1,0), colors.HexColor(\"#f0f0f0\")),\n",
        "        (\"GRID\",(0,0),(-1,-1), 0.3, colors.grey),\n",
        "        (\"FONTNAME\",(0,0),(-1,0),\"Helvetica-Bold\"),\n",
        "        (\"VALIGN\",(0,0),(-1,-1),\"TOP\"),\n",
        "        (\"FONTSIZE\",(0,0),(-1,0),10),\n",
        "        (\"FONTSIZE\",(0,1),(-1,-1),9),\n",
        "    ]))\n",
        "    story.append(tbl)\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(PageBreak())\n",
        "\n",
        "    story.append(Paragraph(\"Detailed Findings\", H2))\n",
        "    story.append(Spacer(1, 8))\n",
        "    for i, (_, r) in enumerate(df.iterrows(), 1):\n",
        "        story.append(Paragraph(f\"{i}. {r.get('cve_id','UNKNOWN')}\", styles[\"Heading3\"]))\n",
        "        story.append(Paragraph(f\"<b>Title:</b> {r.get('title','') or '‚Äî'}\", Normal))\n",
        "        story.append(Paragraph(f\"<b>Priority:</b> {r.get('priority','Unknown')}  |  <b>Effort:</b> {r.get('effort','Unknown')}  |  <b>CVSS:</b> {r.get('cvss_v3','‚Äî')}\", Normal))\n",
        "        story.append(Paragraph(f\"<b>Description:</b> {r.get('description','‚Äî')}\", Normal))\n",
        "        if r.get(\"mitigations\"):\n",
        "            story.append(Paragraph(\"<b>Mitigations:</b>\", Normal))\n",
        "            items = [x.strip() for x in str(r[\"mitigations\"]).split(\",\") if x.strip()]\n",
        "            story.append(ListFlowable([ListItem(Paragraph(x, Normal)) for x in items[:8]]))\n",
        "        if r.get(\"references\"):\n",
        "            story.append(Paragraph(\"<b>References:</b>\", Normal))\n",
        "            refs = [x.strip() for x in str(r[\"references\"]).split(\",\") if x.strip()]\n",
        "            story.append(ListFlowable([ListItem(Paragraph(x, Normal)) for x in refs[:6]]))\n",
        "        story.append(Spacer(1, 10))\n",
        "\n",
        "    doc.build(story)\n",
        "    buf.seek(0)\n",
        "    filename = f\"CyberMind_Report_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.pdf\"\n",
        "    return buf, filename\n",
        "\n",
        "def simple_qa(df, question):\n",
        "    \"\"\"Tiny lexical Q&A over the loaded data.\"\"\"\n",
        "    q = question.lower().strip()\n",
        "    if not len(df): return \"No data loaded yet.\"\n",
        "    scored = []\n",
        "    for _, r in df.iterrows():\n",
        "        text = f\"{r.get('title','')} {r.get('description','')}\".lower()\n",
        "        score = sum(1 for token in q.split() if token in text)\n",
        "        if score > 0:\n",
        "            scored.append((score, r))\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    top = [r for _, r in scored[:3]] if scored else []\n",
        "    lines = [\"Here‚Äôs what I found:\"]\n",
        "    for r in top:\n",
        "        lines.append(f\"- {r.get('cve_id','?')} ‚Äî {r.get('priority','Unknown')}: {(r.get('title') or r.get('description',''))[:80]}...\")\n",
        "    if not top:\n",
        "        lines.append(\"- No exact matches. Try another keyword.\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OpenAI enrichment (no UI changes) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "def _get_openai_client():\n",
        "    \"\"\"\n",
        "    Returns an authenticated OpenAI client using either Streamlit secrets or environment variables.\n",
        "    Works safely on both local machines and Google Colab.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import streamlit as st\n",
        "    from openai import OpenAI\n",
        "\n",
        "    try:\n",
        "        key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "    except Exception:\n",
        "        key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    if not key:\n",
        "        st.error(\"‚ö†Ô∏è No OpenAI API key found. Please set it using os.environ or add secrets.toml file.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        client = OpenAI(api_key=key)\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to initialize OpenAI client: {e}\")\n",
        "        return None\n",
        "    return OpenAI(api_key=key)\n",
        "\n",
        "AI_SYSTEM = (\n",
        "    \"You are a cybersecurity assistant. Given a vulnerability text, \"\n",
        "    \"return a SHORT, ACTIONABLE, JSON object with keys: \"\n",
        "    \"priority (Critical/High/Medium/Low/Unknown), \"\n",
        "    \"category (SQL Injection, XSS, RCE, Auth, Misconfiguration, DoS, InfoLeak, Other), \"\n",
        "    \"summary, mitigations (array), estimated_effort (Low/Medium/High), references (array).\"\n",
        ")\n",
        "\n",
        "def _ai_classify(client, title: str, desc: str) -> dict:\n",
        "    if not client: return {}\n",
        "    prompt = (\n",
        "        \"TEXT:\\n\\\"\\\"\\\"\\n\" + (title or \"\") + \"\\n\" + (desc or \"\") + \"\\n\\\"\\\"\\\"\\n\\n\"\n",
        "        \"Return ONLY valid JSON with keys: priority, category, summary, mitigations, \"\n",
        "        \"estimated_effort, references.\"\n",
        "    )\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=OPENAI_MODEL,\n",
        "            temperature=0.2,\n",
        "            response_format={\"type\":\"json_object\"},\n",
        "            messages=[{\"role\":\"system\",\"content\":AI_SYSTEM},\n",
        "                      {\"role\":\"user\",\"content\":prompt}],\n",
        "        )\n",
        "        return json.loads(resp.choices[0].message.content)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def enrich_df_with_ai(df: pd.DataFrame, batch_size: int = 200) -> pd.DataFrame:\n",
        "    \"\"\"Auto-fill missing priority/description/mitigations via OpenAI; no UI changes.\"\"\"\n",
        "    client = _get_openai_client()\n",
        "    if client is None or df.empty:\n",
        "        return df\n",
        "    need_mask = (\n",
        "        df[\"priority\"].fillna(\"\").eq(\"Unknown\") |\n",
        "        df[\"mitigations\"].fillna(\"\").eq(\"\") |\n",
        "        df[\"description\"].fillna(\"\").eq(\"\")\n",
        "    )\n",
        "    idxs = df[need_mask].head(batch_size).index.tolist()\n",
        "    if not idxs: return df\n",
        "\n",
        "    for rid in idxs:\n",
        "        r = df.loc[rid].to_dict()\n",
        "        ai = _ai_classify(client, r.get(\"title\",\"\"), r.get(\"description\",\"\"))\n",
        "        if isinstance(ai, dict) and ai:\n",
        "            if r.get(\"priority\") in (None, \"\", \"Unknown\"):\n",
        "                df.at[rid, \"priority\"] = ai.get(\"priority\",\"Unknown\")\n",
        "            if not r.get(\"description\"):\n",
        "                df.at[rid, \"description\"] = ai.get(\"summary\",\"\")\n",
        "            if not r.get(\"mitigations\"):\n",
        "                mits = ai.get(\"mitigations\") or []\n",
        "                if isinstance(mits, list):\n",
        "                    df.at[rid, \"mitigations\"] = \", \".join([str(x).strip() for x in mits if str(x).strip()])\n",
        "            if r.get(\"effort\") in (None, \"\", \"Unknown\"):\n",
        "                df.at[rid, \"effort\"] = (ai.get(\"estimated_effort\",\"Unknown\") or \"Unknown\").title()\n",
        "            refs_ai = ai.get(\"references\") or []\n",
        "            if refs_ai:\n",
        "                base = [x.strip() for x in str(r.get(\"references\",\"\")).split(\",\") if x.strip()]\n",
        "                merged = list(dict.fromkeys(base + [str(x).strip() for x in refs_ai if str(x).strip()]))\n",
        "                df.at[rid, \"references\"] = \", \".join(merged)\n",
        "    return df\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Sidebar (input & filters) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "st.sidebar.title(\"üõ† Controls\")\n",
        "uploaded = st.sidebar.file_uploader(\"Upload CyberMind data (JSON / CSV)\", type=[\"json\",\"csv\"])\n",
        "st.sidebar.markdown('<span class=\"cm-sub\">If empty, demo data will be used.</span>', unsafe_allow_html=True)\n",
        "\n",
        "raw = load_any_file(uploaded) if uploaded else DEMO_DATA\n",
        "df = normalize_records(raw)\n",
        "\n",
        "# ‚¨ÖÔ∏è‚¨ÖÔ∏è ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ∞ŸÉÿßÿ° ŸáŸÜÿß (ÿ®ÿØŸàŸÜ ÿ£Ÿä ÿ™ÿ∫ŸäŸäÿ± Ÿàÿßÿ¨Ÿáÿ©)\n",
        "if len(df) and uploaded is not None:\n",
        "    with st.spinner(\"AI enrichment in progress (auto)‚Ä¶\"):\n",
        "        df = enrich_df_with_ai(df, batch_size=200)\n",
        "\n",
        "st.sidebar.divider()\n",
        "query = st.sidebar.text_input(\"Search in CVE / title / description\", \"\")\n",
        "severities = st.sidebar.multiselect(\"Filter by Priority\", [\"All\",\"Critical\",\"High\",\"Medium\",\"Low\",\"Unknown\"], default=[\"All\"])\n",
        "\n",
        "def apply_filters(df, query, severities):\n",
        "    return filter_dataframe(df, query, severities or [\"All\"])\n",
        "\n",
        "filtered = apply_filters(df, query, severities)\n",
        "\n",
        "st.sidebar.divider()\n",
        "st.sidebar.subheader(\"üí¨ Ask CyberMind\")\n",
        "user_q = st.sidebar.text_input(\"Ask (e.g., 'highest risk SQL')\", \"\")\n",
        "if user_q:\n",
        "    st.sidebar.info(simple_qa(filtered, user_q))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Header ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "colA, colB = st.columns([0.7,0.3])\n",
        "with colA:\n",
        "    st.markdown('<div class=\"cm-h1\">CyberMind Dashboard</div>', unsafe_allow_html=True)\n",
        "    st.markdown('<div class=\"cm-sub\">AI-Powered Multi-Agent Cybersecurity Intelligence Framework</div>', unsafe_allow_html=True)\n",
        "with colB:\n",
        "    st.markdown(f'<span class=\"cm-badge\">Live Prototype</span>', unsafe_allow_html=True)\n",
        "    st.caption(f\"Records loaded: {len(df)}  |  Filtered: {len(filtered)}\")\n",
        "st.divider()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ KPIs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "c1, c2, c3, c4 = st.columns(4)\n",
        "with c1: kpi_card(\"Total Findings\", len(filtered))\n",
        "with c2: kpi_card(\"High Priority\", int((filtered[\"priority\"]==\"High\").sum()) if \"priority\" in filtered else 0)\n",
        "with c3: kpi_card(\"With Mitigations\", int(filtered[\"mitigations\"].astype(bool).sum()))\n",
        "with c4: kpi_card(\"Unique Sources\", filtered[\"source\"].nunique() if \"source\" in filtered else 1)\n",
        "st.divider()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Tabs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "t1, t2, t3, t4, t5 = st.tabs([\"Overview\",\"Threats\",\"Vulnerabilities\",\"Mitigations\",\"Report\"])\n",
        "\n",
        "with t1:\n",
        "    st.subheader(\"Overview\")\n",
        "    if len(filtered):\n",
        "        dist = filtered[\"priority\"].fillna(\"Unknown\").value_counts()\n",
        "        fig, ax = plt.subplots()\n",
        "        dist.plot(kind=\"bar\", ax=ax)\n",
        "        ax.set_title(\"Priority Distribution\"); ax.set_xlabel(\"Priority\"); ax.set_ylabel(\"Count\")\n",
        "        st.pyplot(fig)\n",
        "    st.dataframe(filtered[[\"cve_id\",\"title\",\"priority\",\"cvss_v3\",\"source\"]], use_container_width=True, height=360)\n",
        "\n",
        "with t2:\n",
        "    st.subheader(\"Threats (Raw)\")\n",
        "    st.dataframe(filtered[[\"cve_id\",\"title\",\"description\",\"source\"]], use_container_width=True, height=480)\n",
        "\n",
        "with t3:\n",
        "    st.subheader(\"Vulnerabilities\")\n",
        "    left, right = st.columns([0.55, 0.45])\n",
        "    with left:\n",
        "        st.markdown(\"Top items by CVSS (approx)\")\n",
        "        st.dataframe(\n",
        "            filtered.sort_values(\"cvss_numeric\", ascending=False)[[\"cve_id\",\"title\",\"cvss_v3\",\"priority\"]].head(15),\n",
        "            use_container_width=True, height=380\n",
        "        )\n",
        "    with right:\n",
        "        st.markdown(\"CVSS (approx) Histogram\")\n",
        "        if filtered[\"cvss_numeric\"].notna().any():\n",
        "            fig2, ax2 = plt.subplots()\n",
        "            filtered[\"cvss_numeric\"].dropna().plot(kind=\"hist\", bins=8, ax=ax2)\n",
        "            ax2.set_xlabel(\"CVSS (approx)\")\n",
        "            st.pyplot(fig2)\n",
        "        else:\n",
        "            st.info(\"No numeric CVSS parsed from the dataset.\")\n",
        "\n",
        "with t4:\n",
        "    st.subheader(\"Mitigations\")\n",
        "    st.dataframe(filtered[[\"cve_id\",\"priority\",\"mitigations\",\"references\"]], use_container_width=True, height=480)\n",
        "\n",
        "with t5:\n",
        "    st.subheader(\"Generate Report\")\n",
        "    col_pdf, col_json, col_csv = st.columns(3)\n",
        "    with col_pdf:\n",
        "        if st.button(\"üìÑ Generate PDF (ReportLab)\"):\n",
        "            pdf_bytes, fname = make_pdf(filtered)\n",
        "            if pdf_bytes:\n",
        "                st.download_button(\"‚¨áÔ∏è Download PDF\", data=pdf_bytes, file_name=fname, mime=\"application/pdf\")\n",
        "    with col_json:\n",
        "        st.download_button(\n",
        "            \"‚¨áÔ∏è Export JSON\",\n",
        "            data=json.dumps(filtered.to_dict(orient=\"records\"), indent=2),\n",
        "            file_name=f\"cybermind_filtered_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.json\",\n",
        "            mime=\"application/json\"\n",
        "        )\n",
        "    with col_csv:\n",
        "        csv_bytes = filtered.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\n",
        "            \"‚¨áÔ∏è Export CSV\",\n",
        "            data=csv_bytes,\n",
        "            file_name=f\"cybermind_filtered_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "st.caption(\"¬© CyberMind ‚Äî SDA Generative AI / LLM Bootcamp\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mwz0PiQlO9Z",
        "outputId": "c80f59bb-44ab-4388-d3d3-ac3291c633e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C: install cloudflared (deb)\n",
        "!wget -q -O cloudflared.deb \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"\n",
        "!sudo dpkg -i cloudflared.deb || true\n",
        "# if dpkg reports dependencies, try apt-get -f install\n",
        "!sudo apt-get -y -f install\n",
        "!cloudflared --version || echo \"cloudflared not found\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCSnsfIBljx9",
        "outputId": "35bf1f19-373e-4e1a-8c40-5eabca3d6cf7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 121239 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared.deb ...\n",
            "Unpacking cloudflared (2025.11.1) over (2025.11.1) ...\n",
            "Setting up cloudflared (2025.11.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "cloudflared version 2025.11.1 (built 2025-11-07-16:59 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D: start Streamlit in background\n",
        "import subprocess, time, os, signal, pathlib\n",
        "\n",
        "# kill any existing streamlit processes\n",
        "!pkill -f streamlit || true\n",
        "\n",
        "# start streamlit and send logs to file\n",
        "log_stream = \"streamlit.log\"\n",
        "cmd = [\"streamlit\",\"run\",\"app.py\",\"--server.port\",\"8501\",\"--server.enableCORS\",\"false\",\"--server.enableXsrfProtection\",\"false\"]\n",
        "p = subprocess.Popen(cmd, stdout=open(log_stream,\"w\"), stderr=subprocess.STDOUT, text=True)\n",
        "time.sleep(4)\n",
        "print(\"Started Streamlit (pid {}). Logs -> {}\".format(p.pid, log_stream))\n",
        "print(\"Local URL: http://localhost:8501\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmNaSFOflulI",
        "outputId": "9f484be3-f1cf-4031-8d7d-df5fd80dba3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "Started Streamlit (pid 2293). Logs -> streamlit.log\n",
            "Local URL: http://localhost:8501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E: start cloudflared tunnel and extract public URL\n",
        "import subprocess, time, pathlib, re\n",
        "\n",
        "# kill any previous cloudflared\n",
        "!pkill -f cloudflared || true\n",
        "\n",
        "log_path = \"cloudflared.log\"\n",
        "# Start cloudflared (non-blocking)\n",
        "proc = subprocess.Popen([\"cloudflared\",\"tunnel\",\"--url\",\"http://localhost:8501\",\"--no-autoupdate\",\"--logfile\",log_path,\"--loglevel\",\"info\"],\n",
        "                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "# wait and poll the logfile for the public URL\n",
        "public_url = None\n",
        "for i in range(45):  # up to ~45 seconds\n",
        "    time.sleep(1)\n",
        "    if pathlib.Path(log_path).exists():\n",
        "        txt = pathlib.Path(log_path).read_text(errors=\"ignore\")\n",
        "        m = re.search(r\"https://[-a-z0-9]+\\.trycloudflare\\.com\", txt)\n",
        "        if m:\n",
        "            public_url = m.group(0)\n",
        "            break\n",
        "\n",
        "if public_url:\n",
        "    print(\"‚úÖ Public URL:\", public_url)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Couldn't find public URL in cloudflared.log yet.\")\n",
        "    print(\"Last 40 lines from the log:\")\n",
        "    if pathlib.Path(log_path).exists():\n",
        "        print(\"\\n\".join(pathlib.Path(log_path).read_text().splitlines()[-40:]))\n",
        "    else:\n",
        "        print(\"cloudflared.log not found. Check cloudflared installation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq7q8ew9l8Z8",
        "outputId": "f7715daf-f2b4-47f7-9db6-30b3f1ce1d05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "‚úÖ Public URL: https://accordance-declined-algebra-confidence.trycloudflare.com\n"
          ]
        }
      ]
    }
  ]
}